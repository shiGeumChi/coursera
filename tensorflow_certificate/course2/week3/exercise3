{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 74, 74, 32)   864         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 74, 74, 32)   96          conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 74, 74, 32)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 72, 72, 32)   9216        activation_583[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 72, 72, 32)   96          conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 72, 72, 32)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 72, 72, 64)   18432       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 72, 72, 64)   192         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 72, 72, 64)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 35, 35, 64)   0           activation_585[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 35, 35, 80)   240         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 35, 35, 80)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 33, 33, 192)  138240      activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 33, 33, 192)  576         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 33, 33, 192)  0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 16, 16, 192)  0           activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 16, 16, 64)   192         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 16, 16, 64)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 16, 16, 96)   55296       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 16, 16, 48)   144         conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 16, 16, 96)   288         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 16, 16, 48)   0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 16, 16, 96)   0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 16, 16, 64)   76800       activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 16, 16, 96)   82944       activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 16, 16, 64)   192         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 16, 16, 64)   192         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 16, 16, 96)   288         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 16, 16, 32)   96          conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 16, 16, 64)   0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 16, 16, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 16, 16, 96)   0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 16, 16, 32)   0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_588[0][0]             \n",
      "                                                                 activation_590[0][0]             \n",
      "                                                                 activation_593[0][0]             \n",
      "                                                                 activation_594[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 16, 16, 64)   192         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 16, 16, 64)   0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 16, 16, 96)   55296       activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 16, 16, 48)   144         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 16, 16, 96)   288         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 16, 16, 48)   0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 16, 16, 96)   0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 16, 16, 64)   76800       activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 16, 16, 96)   82944       activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 16, 16, 64)   192         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 16, 16, 64)   192         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 16, 16, 96)   288         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 16, 16, 64)   192         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 16, 16, 64)   0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 16, 16, 64)   0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 16, 16, 96)   0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 16, 16, 64)   0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_595[0][0]             \n",
      "                                                                 activation_597[0][0]             \n",
      "                                                                 activation_600[0][0]             \n",
      "                                                                 activation_601[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 16, 16, 64)   192         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 16, 16, 64)   0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 16, 16, 96)   55296       activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 16, 16, 48)   144         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 16, 16, 96)   288         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 16, 16, 48)   0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 16, 16, 96)   0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 16, 16, 64)   76800       activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 16, 16, 96)   82944       activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 16, 16, 64)   192         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 16, 16, 64)   192         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 16, 16, 96)   288         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 16, 16, 64)   192         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 16, 16, 64)   0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 16, 16, 64)   0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 16, 16, 96)   0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 16, 16, 64)   0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_602[0][0]             \n",
      "                                                                 activation_604[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "                                                                 activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 16, 16, 64)   192         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 16, 16, 64)   0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 16, 16, 96)   55296       activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 16, 16, 96)   288         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 16, 16, 96)   0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 7, 7, 96)     82944       activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 7, 7, 384)    1152        conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 7, 7, 96)     288         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 7, 7, 384)    0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 7, 7, 96)     0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_609[0][0]             \n",
      "                                                                 activation_612[0][0]             \n",
      "                                                                 max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 7, 7, 128)    384         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 7, 7, 128)    0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 7, 7, 128)    114688      activation_617[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 7, 7, 128)    384         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 7, 7, 128)    0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 7, 7, 128)    114688      activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 7, 7, 128)    384         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 7, 7, 128)    384         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 7, 7, 128)    0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 7, 7, 128)    0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 7, 7, 128)    114688      activation_614[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 7, 7, 128)    114688      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 7, 7, 128)    384         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 7, 7, 128)    384         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 7, 7, 128)    0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 7, 7, 128)    0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 7, 7, 192)    172032      activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 7, 7, 192)    172032      activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 7, 7, 192)    576         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 7, 7, 192)    576         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 7, 7, 192)    576         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 7, 7, 192)    576         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 7, 7, 192)    0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 7, 7, 192)    0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 7, 7, 192)    0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 7, 7, 192)    0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_613[0][0]             \n",
      "                                                                 activation_616[0][0]             \n",
      "                                                                 activation_621[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 7, 7, 160)    480         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 7, 7, 160)    0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 7, 7, 160)    179200      activation_627[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 7, 7, 160)    480         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 7, 7, 160)    0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 7, 7, 160)    179200      activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 7, 7, 160)    480         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 7, 7, 160)    480         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 7, 7, 160)    0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 7, 7, 160)    0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 7, 7, 160)    179200      activation_624[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 7, 7, 160)    179200      activation_629[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 7, 7, 160)    480         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 7, 7, 160)    480         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 7, 7, 160)    0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 7, 7, 160)    0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 7, 7, 192)    215040      activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 7, 7, 192)    215040      activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 7, 7, 192)    576         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 7, 7, 192)    576         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 7, 7, 192)    576         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 7, 7, 192)    576         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 7, 7, 192)    0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 7, 7, 192)    0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 7, 7, 192)    0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 7, 7, 192)    0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_623[0][0]             \n",
      "                                                                 activation_626[0][0]             \n",
      "                                                                 activation_631[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 7, 7, 160)    480         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 7, 7, 160)    0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 7, 7, 160)    179200      activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 7, 7, 160)    480         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 7, 7, 160)    0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 7, 7, 160)    179200      activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 7, 7, 160)    480         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 7, 7, 160)    480         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 7, 7, 160)    0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 7, 7, 160)    0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 7, 7, 160)    179200      activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 7, 7, 160)    179200      activation_639[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 7, 7, 160)    480         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 7, 7, 160)    480         conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 7, 7, 160)    0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 7, 7, 160)    0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 7, 7, 192)    215040      activation_635[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 7, 7, 192)    215040      activation_640[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 7, 7, 192)    576         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 7, 7, 192)    576         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 7, 7, 192)    576         conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 7, 7, 192)    576         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 7, 7, 192)    0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 7, 7, 192)    0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 7, 7, 192)    0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 7, 7, 192)    0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_633[0][0]             \n",
      "                                                                 activation_636[0][0]             \n",
      "                                                                 activation_641[0][0]             \n",
      "                                                                 activation_642[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 7, 7, 192)    576         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 7, 7, 192)    0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 7, 7, 192)    258048      activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 7, 7, 192)    576         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 7, 7, 192)    0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 7, 7, 192)    258048      activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 7, 7, 192)    576         conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 7, 7, 192)    576         conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 7, 7, 192)    0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 7, 7, 192)    0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 7, 7, 192)    258048      activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 7, 7, 192)    258048      activation_649[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 7, 7, 192)    576         conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 7, 7, 192)    576         conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 7, 7, 192)    0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 7, 7, 192)    0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 7, 7, 192)    258048      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 7, 7, 192)    258048      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 7, 7, 192)    576         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 7, 7, 192)    576         conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 7, 7, 192)    576         conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 7, 7, 192)    576         conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 7, 7, 192)    0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 7, 7, 192)    0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 7, 7, 192)    0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 7, 7, 192)    0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_643[0][0]             \n",
      "                                                                 activation_646[0][0]             \n",
      "                                                                 activation_651[0][0]             \n",
      "                                                                 activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 7, 7, 192)    576         conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 7, 7, 192)    0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 7, 7, 192)    258048      activation_655[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 7, 7, 192)    576         conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 7, 7, 192)    0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 7, 7, 192)    258048      activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 7, 7, 192)    576         conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 7, 7, 192)    576         conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 7, 7, 192)    0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 7, 7, 192)    0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 3, 3, 320)    552960      activation_653[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 3, 3, 192)    331776      activation_657[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 3, 3, 320)    960         conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchN (None, 3, 3, 192)    576         conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 3, 3, 320)    0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_658 (Activation)     (None, 3, 3, 192)    0           batch_normalization_659[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_654[0][0]             \n",
      "                                                                 activation_658[0][0]             \n",
      "                                                                 max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchN (None, 3, 3, 448)    1344        conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_663 (Activation)     (None, 3, 3, 448)    0           batch_normalization_664[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 3, 3, 384)    1548288     activation_663[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchN (None, 3, 3, 384)    1152        conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchN (None, 3, 3, 384)    1152        conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_660 (Activation)     (None, 3, 3, 384)    0           batch_normalization_661[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_664 (Activation)     (None, 3, 3, 384)    0           batch_normalization_665[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 3, 3, 384)    442368      activation_660[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 3, 3, 384)    442368      activation_660[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 3, 3, 384)    442368      activation_664[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 3, 3, 384)    442368      activation_664[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_63 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchN (None, 3, 3, 384)    1152        conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchN (None, 3, 3, 384)    1152        conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_666 (BatchN (None, 3, 3, 384)    1152        conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_667 (BatchN (None, 3, 3, 384)    1152        conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_63[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchN (None, 3, 3, 320)    960         conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_661 (Activation)     (None, 3, 3, 384)    0           batch_normalization_662[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_662 (Activation)     (None, 3, 3, 384)    0           batch_normalization_663[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_665 (Activation)     (None, 3, 3, 384)    0           batch_normalization_666[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_666 (Activation)     (None, 3, 3, 384)    0           batch_normalization_667[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_668 (BatchN (None, 3, 3, 192)    576         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_659 (Activation)     (None, 3, 3, 320)    0           batch_normalization_660[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_661[0][0]             \n",
      "                                                                 activation_662[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 3, 3, 768)    0           activation_665[0][0]             \n",
      "                                                                 activation_666[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_667 (Activation)     (None, 3, 3, 192)    0           batch_normalization_668[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_659[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 3, 3, 448)    1344        conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_672 (Activation)     (None, 3, 3, 448)    0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 3, 3, 384)    1548288     activation_672[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 3, 3, 384)    1152        conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 3, 3, 384)    1152        conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_669 (Activation)     (None, 3, 3, 384)    0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 3, 3, 384)    0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 3, 3, 384)    442368      activation_669[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 3, 3, 384)    442368      activation_669[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 3, 3, 384)    442368      activation_673[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 3, 3, 384)    442368      activation_673[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_64 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 3, 3, 384)    1152        conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 3, 3, 384)    1152        conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 3, 3, 384)    1152        conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_676 (BatchN (None, 3, 3, 384)    1152        conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_64[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_669 (BatchN (None, 3, 3, 320)    960         conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_670 (Activation)     (None, 3, 3, 384)    0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_671 (Activation)     (None, 3, 3, 384)    0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_674 (Activation)     (None, 3, 3, 384)    0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 3, 3, 384)    0           batch_normalization_676[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_677 (BatchN (None, 3, 3, 192)    576         conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_668 (Activation)     (None, 3, 3, 320)    0           batch_normalization_669[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_670[0][0]             \n",
      "                                                                 activation_671[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 3, 3, 768)    0           activation_674[0][0]             \n",
      "                                                                 activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 3, 3, 192)    0           batch_normalization_677[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_668[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 activation_676[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
    "                                include_top = False,\n",
    "                                weights=None)\n",
    "# Your Code Here\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "  # Your Code Here\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')# Your Code Here)\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output# Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 74, 74, 32)   864         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 74, 74, 32)   96          conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 74, 74, 32)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 72, 72, 32)   9216        activation_583[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 72, 72, 32)   96          conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 72, 72, 32)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 72, 72, 64)   18432       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 72, 72, 64)   192         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 72, 72, 64)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 35, 35, 64)   0           activation_585[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 35, 35, 80)   240         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 35, 35, 80)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 33, 33, 192)  138240      activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 33, 33, 192)  576         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 33, 33, 192)  0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 16, 16, 192)  0           activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 16, 16, 64)   192         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 16, 16, 64)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 16, 16, 96)   55296       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 16, 16, 48)   144         conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 16, 16, 96)   288         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 16, 16, 48)   0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 16, 16, 96)   0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 16, 16, 64)   76800       activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 16, 16, 96)   82944       activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 16, 16, 64)   192         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 16, 16, 64)   192         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 16, 16, 96)   288         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 16, 16, 32)   96          conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 16, 16, 64)   0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 16, 16, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 16, 16, 96)   0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 16, 16, 32)   0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_588[0][0]             \n",
      "                                                                 activation_590[0][0]             \n",
      "                                                                 activation_593[0][0]             \n",
      "                                                                 activation_594[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 16, 16, 64)   192         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 16, 16, 64)   0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 16, 16, 96)   55296       activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 16, 16, 48)   144         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 16, 16, 96)   288         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 16, 16, 48)   0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 16, 16, 96)   0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 16, 16, 64)   76800       activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 16, 16, 96)   82944       activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 16, 16, 64)   192         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 16, 16, 64)   192         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 16, 16, 96)   288         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 16, 16, 64)   192         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 16, 16, 64)   0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 16, 16, 64)   0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 16, 16, 96)   0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 16, 16, 64)   0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_595[0][0]             \n",
      "                                                                 activation_597[0][0]             \n",
      "                                                                 activation_600[0][0]             \n",
      "                                                                 activation_601[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 16, 16, 64)   192         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 16, 16, 64)   0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 16, 16, 96)   55296       activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 16, 16, 48)   144         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 16, 16, 96)   288         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 16, 16, 48)   0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 16, 16, 96)   0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 16, 16, 64)   76800       activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 16, 16, 96)   82944       activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 16, 16, 64)   192         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 16, 16, 64)   192         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 16, 16, 96)   288         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 16, 16, 64)   192         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 16, 16, 64)   0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 16, 16, 64)   0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 16, 16, 96)   0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 16, 16, 64)   0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_602[0][0]             \n",
      "                                                                 activation_604[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "                                                                 activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 16, 16, 64)   192         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 16, 16, 64)   0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 16, 16, 96)   55296       activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 16, 16, 96)   288         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 16, 16, 96)   0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 7, 7, 96)     82944       activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 7, 7, 384)    1152        conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 7, 7, 96)     288         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 7, 7, 384)    0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 7, 7, 96)     0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_609[0][0]             \n",
      "                                                                 activation_612[0][0]             \n",
      "                                                                 max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 7, 7, 128)    384         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 7, 7, 128)    0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 7, 7, 128)    114688      activation_617[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 7, 7, 128)    384         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 7, 7, 128)    0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 7, 7, 128)    114688      activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 7, 7, 128)    384         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 7, 7, 128)    384         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 7, 7, 128)    0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 7, 7, 128)    0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 7, 7, 128)    114688      activation_614[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 7, 7, 128)    114688      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 7, 7, 128)    384         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 7, 7, 128)    384         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 7, 7, 128)    0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 7, 7, 128)    0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 7, 7, 192)    172032      activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 7, 7, 192)    172032      activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 7, 7, 192)    576         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 7, 7, 192)    576         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 7, 7, 192)    576         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 7, 7, 192)    576         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 7, 7, 192)    0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 7, 7, 192)    0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 7, 7, 192)    0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 7, 7, 192)    0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_613[0][0]             \n",
      "                                                                 activation_616[0][0]             \n",
      "                                                                 activation_621[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 7, 7, 160)    480         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 7, 7, 160)    0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 7, 7, 160)    179200      activation_627[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 7, 7, 160)    480         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 7, 7, 160)    0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 7, 7, 160)    179200      activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 7, 7, 160)    480         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 7, 7, 160)    480         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 7, 7, 160)    0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 7, 7, 160)    0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 7, 7, 160)    179200      activation_624[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 7, 7, 160)    179200      activation_629[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 7, 7, 160)    480         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 7, 7, 160)    480         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 7, 7, 160)    0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 7, 7, 160)    0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 7, 7, 192)    215040      activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 7, 7, 192)    215040      activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 7, 7, 192)    576         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 7, 7, 192)    576         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 7, 7, 192)    576         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 7, 7, 192)    576         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 7, 7, 192)    0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 7, 7, 192)    0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 7, 7, 192)    0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 7, 7, 192)    0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_623[0][0]             \n",
      "                                                                 activation_626[0][0]             \n",
      "                                                                 activation_631[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 7, 7, 160)    480         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 7, 7, 160)    0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 7, 7, 160)    179200      activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 7, 7, 160)    480         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 7, 7, 160)    0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 7, 7, 160)    179200      activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 7, 7, 160)    480         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 7, 7, 160)    480         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 7, 7, 160)    0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 7, 7, 160)    0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 7, 7, 160)    179200      activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 7, 7, 160)    179200      activation_639[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 7, 7, 160)    480         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 7, 7, 160)    480         conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 7, 7, 160)    0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 7, 7, 160)    0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 7, 7, 192)    215040      activation_635[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 7, 7, 192)    215040      activation_640[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 7, 7, 192)    576         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 7, 7, 192)    576         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 7, 7, 192)    576         conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 7, 7, 192)    576         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 7, 7, 192)    0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 7, 7, 192)    0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 7, 7, 192)    0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 7, 7, 192)    0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_633[0][0]             \n",
      "                                                                 activation_636[0][0]             \n",
      "                                                                 activation_641[0][0]             \n",
      "                                                                 activation_642[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 7, 7, 192)    576         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 7, 7, 192)    0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 7, 7, 192)    258048      activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 7, 7, 192)    576         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 7, 7, 192)    0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 7, 7, 192)    258048      activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 7, 7, 192)    576         conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 7, 7, 192)    576         conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 7, 7, 192)    0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 7, 7, 192)    0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 7, 7, 192)    258048      activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 7, 7, 192)    258048      activation_649[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 7, 7, 192)    576         conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 7, 7, 192)    576         conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 7, 7, 192)    0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 7, 7, 192)    0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 7, 7, 192)    258048      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 7, 7, 192)    258048      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 7, 7, 192)    576         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 7, 7, 192)    576         conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 7, 7, 192)    576         conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 7, 7, 192)    576         conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 7, 7, 192)    0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 7, 7, 192)    0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 7, 7, 192)    0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 7, 7, 192)    0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_643[0][0]             \n",
      "                                                                 activation_646[0][0]             \n",
      "                                                                 activation_651[0][0]             \n",
      "                                                                 activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         38536192    flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024,activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)           \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1,activation='sigmoid')(x)      \n",
    "\n",
    "model = Model(pre_trained_model.input,x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = '/tmp/training/horses'# Your Code Here\n",
    "train_humans_dir = '/tmp/training/humans'# Your Code Here\n",
    "validation_horses_dir = '/tmp/validation/horses'# Your Code Here\n",
    "validation_humans_dir = '/tmp/validation/humans'# Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)# Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest'\n",
    "                                  )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale =1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode='binary',\n",
    "                                                   target_size=(150,150))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode='binary',\n",
    "                                                   target_size=(150,150))\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.3146 - acc: 0.8835 - val_loss: 0.0525 - val_acc: 0.9833\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 0.0894 - acc: 0.9660 - val_loss: 0.0406 - val_acc: 0.9875\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 0.0975 - acc: 0.9625 - val_loss: 0.0049 - val_acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()# Your Code Here\n",
    "history = model.fit_generator(train_generator,\n",
    "                             validation_data = validation_generator,\n",
    "                             steps_per_epoch = 50,\n",
    "                             epochs = 3,\n",
    "                             validation_steps = 12,\n",
    "                             verbose =1,\n",
    "                             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
